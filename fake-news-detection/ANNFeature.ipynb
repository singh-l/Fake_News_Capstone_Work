{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This module trains and tests ANN on linguistic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make necessary imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the data\n",
    "df=pd.read_csv('featured_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "      <th>count_punct</th>\n",
       "      <th>t_sentiment</th>\n",
       "      <th>Readability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>89</td>\n",
       "      <td>0.1531</td>\n",
       "      <td>16.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>77</td>\n",
       "      <td>-0.7112</td>\n",
       "      <td>19.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Why the Truth Might Get You FiredWhy the Truth...</td>\n",
       "      <td>184</td>\n",
       "      <td>0.9954</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>51</td>\n",
       "      <td>-0.9993</td>\n",
       "      <td>23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.9753</td>\n",
       "      <td>86.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18280</th>\n",
       "      <td>20795</td>\n",
       "      <td>20795</td>\n",
       "      <td>Rapper T.I.: Trump a ’Poster Child For White S...</td>\n",
       "      <td>Jerome Hudson</td>\n",
       "      <td>Rapper T. I. unloaded on black celebrities who...</td>\n",
       "      <td>0</td>\n",
       "      <td>Rapper T.I.: Trump a ’Poster Child For White S...</td>\n",
       "      <td>48</td>\n",
       "      <td>0.3313</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18281</th>\n",
       "      <td>20796</td>\n",
       "      <td>20796</td>\n",
       "      <td>N.F.L. Playoffs: Schedule, Matchups and Odds -...</td>\n",
       "      <td>Benjamin Hoffman</td>\n",
       "      <td>When the Green Bay Packers lost to the Washing...</td>\n",
       "      <td>0</td>\n",
       "      <td>N.F.L. Playoffs: Schedule, Matchups and Odds -...</td>\n",
       "      <td>186</td>\n",
       "      <td>-0.9723</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18282</th>\n",
       "      <td>20797</td>\n",
       "      <td>20797</td>\n",
       "      <td>Macy’s Is Said to Receive Takeover Approach by...</td>\n",
       "      <td>Michael J. de la Merced and Rachel Abrams</td>\n",
       "      <td>The Macy’s of today grew from the union of sev...</td>\n",
       "      <td>0</td>\n",
       "      <td>Macy’s Is Said to Receive Takeover Approach by...</td>\n",
       "      <td>108</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18283</th>\n",
       "      <td>20798</td>\n",
       "      <td>20798</td>\n",
       "      <td>NATO, Russia To Hold Parallel Exercises In Bal...</td>\n",
       "      <td>Alex Ansary</td>\n",
       "      <td>NATO, Russia To Hold Parallel Exercises In Bal...</td>\n",
       "      <td>1</td>\n",
       "      <td>NATO, Russia To Hold Parallel Exercises In Bal...</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>50.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18284</th>\n",
       "      <td>20799</td>\n",
       "      <td>20799</td>\n",
       "      <td>What Keeps the F-35 Alive</td>\n",
       "      <td>David Swanson</td>\n",
       "      <td>David Swanson is an author, activist, journa...</td>\n",
       "      <td>1</td>\n",
       "      <td>What Keeps the F-35 Alive  David Swanson is an...</td>\n",
       "      <td>294</td>\n",
       "      <td>-0.9978</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18285 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     id                                              title  \\\n",
       "0               0      0  House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
       "1               1      1  FLYNN: Hillary Clinton, Big Woman on Campus - ...   \n",
       "2               2      2                  Why the Truth Might Get You Fired   \n",
       "3               3      3  15 Civilians Killed In Single US Airstrike Hav...   \n",
       "4               4      4  Iranian woman jailed for fictional unpublished...   \n",
       "...           ...    ...                                                ...   \n",
       "18280       20795  20795  Rapper T.I.: Trump a ’Poster Child For White S...   \n",
       "18281       20796  20796  N.F.L. Playoffs: Schedule, Matchups and Odds -...   \n",
       "18282       20797  20797  Macy’s Is Said to Receive Takeover Approach by...   \n",
       "18283       20798  20798  NATO, Russia To Hold Parallel Exercises In Bal...   \n",
       "18284       20799  20799                          What Keeps the F-35 Alive   \n",
       "\n",
       "                                          author  \\\n",
       "0                                  Darrell Lucus   \n",
       "1                                Daniel J. Flynn   \n",
       "2                             Consortiumnews.com   \n",
       "3                                Jessica Purkiss   \n",
       "4                                 Howard Portnoy   \n",
       "...                                          ...   \n",
       "18280                              Jerome Hudson   \n",
       "18281                           Benjamin Hoffman   \n",
       "18282  Michael J. de la Merced and Rachel Abrams   \n",
       "18283                                Alex Ansary   \n",
       "18284                              David Swanson   \n",
       "\n",
       "                                                    text  label  \\\n",
       "0      House Dem Aide: We Didn’t Even See Comey’s Let...      1   \n",
       "1      Ever get the feeling your life circles the rou...      0   \n",
       "2      Why the Truth Might Get You Fired October 29, ...      1   \n",
       "3      Videos 15 Civilians Killed In Single US Airstr...      1   \n",
       "4      Print \\nAn Iranian woman has been sentenced to...      1   \n",
       "...                                                  ...    ...   \n",
       "18280  Rapper T. I. unloaded on black celebrities who...      0   \n",
       "18281  When the Green Bay Packers lost to the Washing...      0   \n",
       "18282  The Macy’s of today grew from the union of sev...      0   \n",
       "18283  NATO, Russia To Hold Parallel Exercises In Bal...      1   \n",
       "18284    David Swanson is an author, activist, journa...      1   \n",
       "\n",
       "                                                 content  count_punct  \\\n",
       "0      House Dem Aide: We Didn’t Even See Comey’s Let...           89   \n",
       "1      FLYNN: Hillary Clinton, Big Woman on Campus - ...           77   \n",
       "2      Why the Truth Might Get You FiredWhy the Truth...          184   \n",
       "3      15 Civilians Killed In Single US Airstrike Hav...           51   \n",
       "4      Iranian woman jailed for fictional unpublished...           16   \n",
       "...                                                  ...          ...   \n",
       "18280  Rapper T.I.: Trump a ’Poster Child For White S...           48   \n",
       "18281  N.F.L. Playoffs: Schedule, Matchups and Odds -...          186   \n",
       "18282  Macy’s Is Said to Receive Takeover Approach by...          108   \n",
       "18283  NATO, Russia To Hold Parallel Exercises In Bal...           33   \n",
       "18284  What Keeps the F-35 Alive  David Swanson is an...          294   \n",
       "\n",
       "       t_sentiment  Readability  \n",
       "0           0.1531         16.1  \n",
       "1          -0.7112         19.3  \n",
       "2           0.9954         22.4  \n",
       "3          -0.9993         23.1  \n",
       "4          -0.9753         86.1  \n",
       "...            ...          ...  \n",
       "18280       0.3313         19.1  \n",
       "18281      -0.9723         11.0  \n",
       "18282       0.9924         13.2  \n",
       "18283       0.0000         50.9  \n",
       "18284      -0.9978         17.5  \n",
       "\n",
       "[18285 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "sc=StandardScaler()\n",
    "df.loc[:,'count_punct':'Readability']=sc.fit_transform(df.loc[:,'count_punct':'Readability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(df.loc[:,'count_punct':'Readability'], df['label'], test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the model\n",
    "def build_classifier():\n",
    "    clf=Sequential()\n",
    "    clf.add(Dense(output_dim=2,init='uniform',activation='relu',input_dim=3))\n",
    "    clf.add(Dense(output_dim=1,init='uniform',activation='sigmoid'))\n",
    "    clf.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make necessary imports\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#train and using k fold cross validation\n",
    "clf=KerasClassifier(build_fn=build_classifier, batch_size=10, nb_epoch=100)\n",
    "accuracies=cross_val_score(estimator=clf, X=x_train,y=y_train,cv=10,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65071768, 0.61517429, 0.57279563, 0.62200958, 0.60902256,\n",
       "       0.62064254, 0.63021189, 0.65618593, 0.59849519, 0.57318741])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see accuracies\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lovedeepsingh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=3, units=2, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/lovedeepsingh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14628/14628 [==============================] - 5s 337us/step - loss: 0.6701 - accuracy: 0.5954\n",
      "Epoch 2/100\n",
      "14628/14628 [==============================] - 4s 239us/step - loss: 0.6354 - accuracy: 0.6285\n",
      "Epoch 3/100\n",
      "14628/14628 [==============================] - 6s 413us/step - loss: 0.6251 - accuracy: 0.6293\n",
      "Epoch 4/100\n",
      "14628/14628 [==============================] - 5s 322us/step - loss: 0.6221 - accuracy: 0.6319\n",
      "Epoch 5/100\n",
      "14628/14628 [==============================] - 6s 428us/step - loss: 0.6207 - accuracy: 0.6317\n",
      "Epoch 6/100\n",
      "14628/14628 [==============================] - 4s 271us/step - loss: 0.6198 - accuracy: 0.6328\n",
      "Epoch 7/100\n",
      "14628/14628 [==============================] - 8s 547us/step - loss: 0.6192 - accuracy: 0.6308\n",
      "Epoch 8/100\n",
      "14628/14628 [==============================] - 8s 531us/step - loss: 0.6185 - accuracy: 0.6314\n",
      "Epoch 9/100\n",
      "14628/14628 [==============================] - 6s 440us/step - loss: 0.6180 - accuracy: 0.6334\n",
      "Epoch 10/100\n",
      "14628/14628 [==============================] - 7s 471us/step - loss: 0.6174 - accuracy: 0.6319\n",
      "Epoch 11/100\n",
      "14628/14628 [==============================] - 6s 437us/step - loss: 0.6171 - accuracy: 0.6347\n",
      "Epoch 12/100\n",
      "14628/14628 [==============================] - 4s 306us/step - loss: 0.6165 - accuracy: 0.6419\n",
      "Epoch 13/100\n",
      "14628/14628 [==============================] - 4s 269us/step - loss: 0.6162 - accuracy: 0.6440\n",
      "Epoch 14/100\n",
      "14628/14628 [==============================] - 5s 323us/step - loss: 0.6159 - accuracy: 0.6427\n",
      "Epoch 15/100\n",
      "14628/14628 [==============================] - 7s 476us/step - loss: 0.6154 - accuracy: 0.64680s -\n",
      "Epoch 16/100\n",
      "14628/14628 [==============================] - 6s 398us/step - loss: 0.6151 - accuracy: 0.6444\n",
      "Epoch 17/100\n",
      "14628/14628 [==============================] - 4s 261us/step - loss: 0.6151 - accuracy: 0.6453\n",
      "Epoch 18/100\n",
      "14628/14628 [==============================] - 4s 254us/step - loss: 0.6148 - accuracy: 0.6468\n",
      "Epoch 19/100\n",
      "14628/14628 [==============================] - 6s 438us/step - loss: 0.6143 - accuracy: 0.6481\n",
      "Epoch 20/100\n",
      "14628/14628 [==============================] - 5s 334us/step - loss: 0.6140 - accuracy: 0.6486\n",
      "Epoch 21/100\n",
      "14628/14628 [==============================] - 4s 298us/step - loss: 0.6139 - accuracy: 0.6491\n",
      "Epoch 22/100\n",
      "14628/14628 [==============================] - 5s 319us/step - loss: 0.6135 - accuracy: 0.6480\n",
      "Epoch 23/100\n",
      "14628/14628 [==============================] - 5s 313us/step - loss: 0.6133 - accuracy: 0.6509\n",
      "Epoch 24/100\n",
      "14628/14628 [==============================] - 7s 490us/step - loss: 0.6130 - accuracy: 0.6509\n",
      "Epoch 25/100\n",
      "14628/14628 [==============================] - 9s 628us/step - loss: 0.6126 - accuracy: 0.6546\n",
      "Epoch 26/100\n",
      "14628/14628 [==============================] - 4s 277us/step - loss: 0.6124 - accuracy: 0.65480s - loss: 0.6134 - accuracy: 0.\n",
      "Epoch 27/100\n",
      "14628/14628 [==============================] - 4s 256us/step - loss: 0.6119 - accuracy: 0.6544\n",
      "Epoch 28/100\n",
      "14628/14628 [==============================] - 5s 319us/step - loss: 0.6114 - accuracy: 0.6577\n",
      "Epoch 29/100\n",
      "14628/14628 [==============================] - 6s 381us/step - loss: 0.6106 - accuracy: 0.6570\n",
      "Epoch 30/100\n",
      "14628/14628 [==============================] - 4s 280us/step - loss: 0.6099 - accuracy: 0.6581\n",
      "Epoch 31/100\n",
      "14628/14628 [==============================] - 5s 345us/step - loss: 0.6088 - accuracy: 0.6611\n",
      "Epoch 32/100\n",
      "14628/14628 [==============================] - 5s 349us/step - loss: 0.6072 - accuracy: 0.6624\n",
      "Epoch 33/100\n",
      "14628/14628 [==============================] - 4s 275us/step - loss: 0.6054 - accuracy: 0.6648\n",
      "Epoch 34/100\n",
      "14628/14628 [==============================] - 5s 346us/step - loss: 0.6034 - accuracy: 0.6666\n",
      "Epoch 35/100\n",
      "14628/14628 [==============================] - 4s 270us/step - loss: 0.6007 - accuracy: 0.6712\n",
      "Epoch 36/100\n",
      "14628/14628 [==============================] - 4s 245us/step - loss: 0.5984 - accuracy: 0.6750\n",
      "Epoch 37/100\n",
      "14628/14628 [==============================] - 4s 265us/step - loss: 0.5958 - accuracy: 0.6796\n",
      "Epoch 38/100\n",
      "14628/14628 [==============================] - 5s 328us/step - loss: 0.5936 - accuracy: 0.6829\n",
      "Epoch 39/100\n",
      "14628/14628 [==============================] - 4s 249us/step - loss: 0.5914 - accuracy: 0.6850\n",
      "Epoch 40/100\n",
      "14628/14628 [==============================] - 4s 255us/step - loss: 0.5889 - accuracy: 0.6883\n",
      "Epoch 41/100\n",
      "14628/14628 [==============================] - 4s 278us/step - loss: 0.5865 - accuracy: 0.6879\n",
      "Epoch 42/100\n",
      "14628/14628 [==============================] - 5s 317us/step - loss: 0.5851 - accuracy: 0.6916\n",
      "Epoch 43/100\n",
      "14628/14628 [==============================] - 5s 354us/step - loss: 0.5834 - accuracy: 0.6940\n",
      "Epoch 44/100\n",
      "14628/14628 [==============================] - 4s 278us/step - loss: 0.5822 - accuracy: 0.6922\n",
      "Epoch 45/100\n",
      "14628/14628 [==============================] - 4s 293us/step - loss: 0.5808 - accuracy: 0.6952\n",
      "Epoch 46/100\n",
      "14628/14628 [==============================] - 6s 408us/step - loss: 0.5797 - accuracy: 0.6976\n",
      "Epoch 47/100\n",
      "14628/14628 [==============================] - 5s 349us/step - loss: 0.5791 - accuracy: 0.6978\n",
      "Epoch 48/100\n",
      "14628/14628 [==============================] - 5s 362us/step - loss: 0.5784 - accuracy: 0.6958\n",
      "Epoch 49/100\n",
      "14628/14628 [==============================] - 5s 325us/step - loss: 0.5778 - accuracy: 0.6987\n",
      "Epoch 50/100\n",
      "14628/14628 [==============================] - 4s 270us/step - loss: 0.5774 - accuracy: 0.6983\n",
      "Epoch 51/100\n",
      "14628/14628 [==============================] - 4s 283us/step - loss: 0.5772 - accuracy: 0.70011s - loss: 0\n",
      "Epoch 52/100\n",
      "14628/14628 [==============================] - 4s 304us/step - loss: 0.5767 - accuracy: 0.7002\n",
      "Epoch 53/100\n",
      "14628/14628 [==============================] - 4s 271us/step - loss: 0.5767 - accuracy: 0.7013\n",
      "Epoch 54/100\n",
      "14628/14628 [==============================] - 4s 276us/step - loss: 0.5764 - accuracy: 0.6998\n",
      "Epoch 55/100\n",
      "14628/14628 [==============================] - 4s 271us/step - loss: 0.5763 - accuracy: 0.70020s - loss: 0.5768 - accuracy: 0.69\n",
      "Epoch 56/100\n",
      "14628/14628 [==============================] - 4s 267us/step - loss: 0.5760 - accuracy: 0.7004\n",
      "Epoch 57/100\n",
      "14628/14628 [==============================] - 4s 267us/step - loss: 0.5760 - accuracy: 0.7013\n",
      "Epoch 58/100\n",
      "14628/14628 [==============================] - 4s 266us/step - loss: 0.5759 - accuracy: 0.7037\n",
      "Epoch 59/100\n",
      "14628/14628 [==============================] - 4s 274us/step - loss: 0.5757 - accuracy: 0.70020s\n",
      "Epoch 60/100\n",
      "14628/14628 [==============================] - 4s 278us/step - loss: 0.5757 - accuracy: 0.7020\n",
      "Epoch 61/100\n",
      "14628/14628 [==============================] - 5s 314us/step - loss: 0.5756 - accuracy: 0.7019\n",
      "Epoch 62/100\n",
      "14628/14628 [==============================] - 4s 297us/step - loss: 0.5758 - accuracy: 0.7027\n",
      "Epoch 63/100\n",
      "14628/14628 [==============================] - 5s 368us/step - loss: 0.5757 - accuracy: 0.7009\n",
      "Epoch 64/100\n",
      "14628/14628 [==============================] - 4s 263us/step - loss: 0.5755 - accuracy: 0.7023\n",
      "Epoch 65/100\n",
      "14628/14628 [==============================] - 4s 269us/step - loss: 0.5755 - accuracy: 0.7009\n",
      "Epoch 66/100\n",
      "14628/14628 [==============================] - 5s 369us/step - loss: 0.5753 - accuracy: 0.7015\n",
      "Epoch 67/100\n",
      "14628/14628 [==============================] - 4s 259us/step - loss: 0.5756 - accuracy: 0.7003\n",
      "Epoch 68/100\n",
      "14628/14628 [==============================] - 4s 274us/step - loss: 0.5754 - accuracy: 0.7011\n",
      "Epoch 69/100\n",
      "14628/14628 [==============================] - 4s 290us/step - loss: 0.5755 - accuracy: 0.7005\n",
      "Epoch 70/100\n",
      "14628/14628 [==============================] - 6s 403us/step - loss: 0.5755 - accuracy: 0.7019\n",
      "Epoch 71/100\n",
      "14628/14628 [==============================] - 6s 413us/step - loss: 0.5754 - accuracy: 0.7002\n",
      "Epoch 72/100\n",
      "14628/14628 [==============================] - 4s 305us/step - loss: 0.5753 - accuracy: 0.7017\n",
      "Epoch 73/100\n",
      "14628/14628 [==============================] - 5s 314us/step - loss: 0.5753 - accuracy: 0.7005\n",
      "Epoch 74/100\n",
      "14628/14628 [==============================] - 4s 305us/step - loss: 0.5754 - accuracy: 0.7006\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14628/14628 [==============================] - 4s 273us/step - loss: 0.5752 - accuracy: 0.7021\n",
      "Epoch 76/100\n",
      "14628/14628 [==============================] - 4s 264us/step - loss: 0.5753 - accuracy: 0.7009\n",
      "Epoch 77/100\n",
      "14628/14628 [==============================] - 4s 249us/step - loss: 0.5752 - accuracy: 0.7015\n",
      "Epoch 78/100\n",
      "14628/14628 [==============================] - 4s 251us/step - loss: 0.5753 - accuracy: 0.7024\n",
      "Epoch 79/100\n",
      "14628/14628 [==============================] - 4s 248us/step - loss: 0.5753 - accuracy: 0.7013\n",
      "Epoch 80/100\n",
      "14628/14628 [==============================] - 4s 255us/step - loss: 0.5751 - accuracy: 0.7008\n",
      "Epoch 81/100\n",
      "14628/14628 [==============================] - 4s 252us/step - loss: 0.5754 - accuracy: 0.7017\n",
      "Epoch 82/100\n",
      "14628/14628 [==============================] - 4s 264us/step - loss: 0.5754 - accuracy: 0.70231s - loss: 0.5745  - ETA: 0s - loss:\n",
      "Epoch 83/100\n",
      "14628/14628 [==============================] - 6s 397us/step - loss: 0.5754 - accuracy: 0.7011\n",
      "Epoch 84/100\n",
      "14628/14628 [==============================] - 5s 311us/step - loss: 0.5753 - accuracy: 0.7019\n",
      "Epoch 85/100\n",
      "14628/14628 [==============================] - 4s 253us/step - loss: 0.5753 - accuracy: 0.7019\n",
      "Epoch 86/100\n",
      "14628/14628 [==============================] - 4s 269us/step - loss: 0.5752 - accuracy: 0.7021\n",
      "Epoch 87/100\n",
      "14628/14628 [==============================] - 4s 262us/step - loss: 0.5753 - accuracy: 0.7011\n",
      "Epoch 88/100\n",
      "14628/14628 [==============================] - 4s 257us/step - loss: 0.5753 - accuracy: 0.7012\n",
      "Epoch 89/100\n",
      "14628/14628 [==============================] - 4s 304us/step - loss: 0.5753 - accuracy: 0.7010\n",
      "Epoch 90/100\n",
      "14628/14628 [==============================] - 6s 433us/step - loss: 0.5752 - accuracy: 0.7015\n",
      "Epoch 91/100\n",
      "14628/14628 [==============================] - 4s 281us/step - loss: 0.5754 - accuracy: 0.7021\n",
      "Epoch 92/100\n",
      "14628/14628 [==============================] - 4s 287us/step - loss: 0.5754 - accuracy: 0.7011\n",
      "Epoch 93/100\n",
      "14628/14628 [==============================] - 5s 318us/step - loss: 0.5752 - accuracy: 0.7024\n",
      "Epoch 94/100\n",
      "14628/14628 [==============================] - 5s 350us/step - loss: 0.5752 - accuracy: 0.7012\n",
      "Epoch 95/100\n",
      "14628/14628 [==============================] - 4s 252us/step - loss: 0.5753 - accuracy: 0.7008\n",
      "Epoch 96/100\n",
      "14628/14628 [==============================] - 4s 294us/step - loss: 0.5753 - accuracy: 0.7016\n",
      "Epoch 97/100\n",
      "14628/14628 [==============================] - 6s 425us/step - loss: 0.5750 - accuracy: 0.7007\n",
      "Epoch 98/100\n",
      "14628/14628 [==============================] - 4s 279us/step - loss: 0.5753 - accuracy: 0.7011\n",
      "Epoch 99/100\n",
      "14628/14628 [==============================] - 4s 269us/step - loss: 0.5753 - accuracy: 0.7002\n",
      "Epoch 100/100\n",
      "14628/14628 [==============================] - 4s 262us/step - loss: 0.5754 - accuracy: 0.7013\n",
      "algorithm - test dataset accuracy\n",
      "ANNFeature -  0.7153\n"
     ]
    }
   ],
   "source": [
    "#fit on training data and check accuracies on both test and valid data\n",
    "clf.fit(x_train, y_train, batch_size=10, nb_epoch=100)\n",
    "y_test_pred = clf.predict(x_test)\n",
    "print('algorithm - test dataset accuracy')\n",
    "print('ANNFeature - ' ,round(accuracy_score(y_test, y_test_pred),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
